# ---
# jupyter:
#   jupytext:
#     formats: py:percent
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
#       jupytext_version: 1.17.1
#   kernelspec:
#     display_name: Python 3 (ipykernel)
#     language: python
#     name: python3
# ---

# %% [markdown]
# cd C:\Users\user\iwaiwa\0801_ã‚¯ãƒ©ã‚¹ã‚¿ã¨äºˆæ¸¬UI
#
# streamlit run 3.py

# %%
import streamlit as st
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import plotly.graph_objects as go
from scipy.interpolate import interp1d

st.set_page_config(layout="wide")
st.title("ğŸ’´ Van Westendorp PSM + ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æã‚¢ãƒ—ãƒª")

@st.cache_data
def load_data(uploaded_file):
    return pd.read_csv(uploaded_file)

def find_intersection(y1, y2, x):
    diff = np.array(y1) - np.array(y2)
    sign_change = np.where(np.diff(np.sign(diff)) != 0)[0]
    if len(sign_change) == 0:
        return None
    i = sign_change[0]
    try:
        f = interp1d(diff[i:i+2], x[i:i+2])
        return float(f(0))
    except Exception:
        return None

uploaded_file = st.file_uploader("ğŸ“‚ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"])

if uploaded_file is not None:
    df = load_data(uploaded_file)
    st.markdown("#### ğŸ” çµã‚Šè¾¼ã¿ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if 'å¹´é½¢' in df.columns:
            min_age = int(df['å¹´é½¢'].min())
            max_age = int(df['å¹´é½¢'].max())
            selected_age_range = st.slider("ğŸ” å¹´é½¢ç¯„å›²", min_age, max_age, (min_age, max_age))
        else:
            selected_age_range = None
    
        # æ€§åˆ¥ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        if 'æ€§åˆ¥' in df.columns:
            gender_options = df['æ€§åˆ¥'].dropna().unique().tolist()
            if 'selected_gender' not in st.session_state:
                st.session_state.selected_gender = gender_options
            selected_gender = st.multiselect(
                "ğŸ” æ€§åˆ¥", options=gender_options, default=st.session_state.selected_gender
            )
            st.session_state.selected_gender = selected_gender
        else:
            selected_gender = None
    
        # è·æ¥­ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        if 'è·æ¥­' in df.columns:
            job_options = df['è·æ¥­'].dropna().unique().tolist()
            if 'selected_jobs' not in st.session_state:
                st.session_state.selected_jobs = job_options
            selected_jobs = st.multiselect(
                "ğŸ” è·æ¥­", options=job_options, default=st.session_state.selected_jobs
            )
            st.session_state.selected_jobs = selected_jobs
        else:
            selected_jobs = None
    
        if 'å¹³å‡è³¼å…¥å˜ä¾¡' in df.columns:
            min_price = int(df['å¹³å‡è³¼å…¥å˜ä¾¡'].min())
            max_price = int(df['å¹³å‡è³¼å…¥å˜ä¾¡'].max())
            selected_average_bands = st.slider("ğŸ” å¹³å‡è³¼å…¥å˜ä¾¡", min_price, max_price, (min_price, max_price))
        else:
            selected_average_bands = None
    
        if 'SNSåˆ©ç”¨æ™‚é–“' in df.columns:
            min_sns = int(df['SNSåˆ©ç”¨æ™‚é–“'].min())
            max_sns = int(df['SNSåˆ©ç”¨æ™‚é–“'].max())
            selected_sns = st.slider("ğŸ” SNSåˆ©ç”¨æ™‚é–“", min_sns, max_sns, (min_sns, max_sns))
        else:
            selected_sns = None
    
    with col2:
        # ã‚­ãƒ£ãƒ©å‚¾å‘ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        if 'ã‚­ãƒ£ãƒ©å‚¾å‘' in df.columns:
            char_options = df['ã‚­ãƒ£ãƒ©å‚¾å‘'].dropna().unique().tolist()
            if 'selected_character' not in st.session_state:
                st.session_state.selected_character = char_options
            selected_character = st.multiselect(
                "ğŸ” ã‚­ãƒ£ãƒ©å‚¾å‘", options=char_options, default=st.session_state.selected_character
            )
            st.session_state.selected_character = selected_character
        else:
            selected_character = None
    
        # é‡è¦è¦–ã™ã‚‹ã“ã¨1 ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        if 'é‡è¦è¦–ã™ã‚‹ã“ã¨' in df.columns:
            imp_options = df['é‡è¦è¦–ã™ã‚‹ã“ã¨'].dropna().unique().tolist()
            if 'selected_importance' not in st.session_state:
                st.session_state.selected_importance = imp_options
            selected_importance = st.multiselect(
                "ğŸ” é‡è¦è¦–ã™ã‚‹ã“ã¨", options=imp_options, default=st.session_state.selected_importance
            )
            st.session_state.selected_importance = selected_importance
        else:
            selected_importance = None
    
        # è³¼è²·é »åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        if 'è³¼è²·é »åº¦' in df.columns:
            freq_options = df['è³¼è²·é »åº¦'].dropna().unique().tolist()
            if 'selected_frequency' not in st.session_state:
                st.session_state.selected_frequency = freq_options
            selected_frequency = st.multiselect(
                "ğŸ” è³¼è²·é »åº¦", options=freq_options, default=st.session_state.selected_frequency
            )
            st.session_state.selected_frequency = selected_frequency
        else:
            selected_frequency = None
    
    with col3:
        if 'è³¼å…¥ã‚¹ã‚¿ã‚¤ãƒ«' in df.columns:
            style_options = df['è³¼å…¥ã‚¹ã‚¿ã‚¤ãƒ«'].dropna().unique().tolist()
            st.markdown("ğŸ” è³¼å…¥ã‚¹ã‚¿ã‚¤ãƒ«")
    
            if "selected_style" not in st.session_state:
                st.session_state.selected_style = {s: True for s in style_options}
    
            colA, colB = st.columns(2)
            with colA:
                if st.button("âœ… å…¨ã¦é¸æŠ"):
                    for s in style_options:
                        st.session_state.selected_style[s] = True
            with colB:
                if st.button("âŒ å…¨ã¦è§£é™¤"):
                    for s in style_options:
                        st.session_state.selected_style[s] = False
    
            selected_style = []
            for s in style_options:
                checked = st.checkbox(s, value=st.session_state.selected_style[s])
                st.session_state.selected_style[s] = checked
                if checked:
                    selected_style.append(s)
        else:
            selected_style = None
            
    # ================
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†
    # ================
    filtered_df = df.copy()
    if selected_age_range:
        filtered_df = filtered_df[filtered_df['å¹´é½¢'].between(*selected_age_range)]
    if selected_gender:
        filtered_df = filtered_df[filtered_df['æ€§åˆ¥'].isin(selected_gender)]
    if selected_jobs:
        filtered_df = filtered_df[filtered_df['è·æ¥­'].isin(selected_jobs)]
    if selected_character:
        filtered_df = filtered_df[filtered_df['ã‚­ãƒ£ãƒ©å‚¾å‘'].isin(selected_character)]
    if selected_frequency:
        filtered_df = filtered_df[filtered_df['è³¼è²·é »åº¦'].isin(selected_frequency)]
    if selected_style:
        filtered_df = filtered_df[filtered_df['è³¼å…¥ã‚¹ã‚¿ã‚¤ãƒ«'].isin(selected_style)]
    if selected_importance:
        filtered_df = filtered_df[filtered_df['é‡è¦è¦–ã™ã‚‹ã“ã¨'].isin(selected_importance)]
    if selected_sns:
        filtered_df = filtered_df[filtered_df['SNSåˆ©ç”¨æ™‚é–“'].between(*selected_sns)]
    if selected_average_bands:
        filtered_df = filtered_df[filtered_df['å¹³å‡è³¼å…¥å˜ä¾¡'].between(*selected_average_bands)]

    st.markdown(f"#### <ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œã®å¯¾è±¡è€…æ•°: {len(filtered_df)} äºº>")

    # ======================
    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
    # ======================
    st.markdown("### ğŸ§© ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°è¨­å®š")

    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã«ä½¿ã†ç‰¹å¾´é‡é¸æŠUIï¼ˆã‚«ãƒ†ã‚´ãƒªã¯ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼‰
    candidate_features = ['å¹´é½¢', 'æ€§åˆ¥','è·æ¥­','è³¼è²·é »åº¦','å¹³å‡è³¼å…¥å˜ä¾¡', 'è³¼å…¥ã‚¹ã‚¿ã‚¤ãƒ«', 'é‡è¦è¦–ã™ã‚‹ã“ã¨']
    selected_features = st.multiselect("ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã«ä½¿ã†å±æ€§ã‚’é¸æŠã—ã¦ãã ã•ã„", candidate_features, default=candidate_features)

    if len(selected_features) == 0:
        st.warning("å°‘ãªãã¨ã‚‚1ã¤ä»¥ä¸Šã®ç‰¹å¾´é‡ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    else:
        cluster_count = st.slider("ã‚¯ãƒ©ã‚¹ã‚¿æ•° (K)", 2, 10, 3)

        # å‰å‡¦ç†ï¼šã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã¯label encodingï¼ˆç°¡æ˜“ç‰ˆï¼‰
        from sklearn.preprocessing import LabelEncoder
        X = filtered_df[selected_features].copy()

        for col in X.columns:
            if X[col].dtype == 'object' or X[col].dtype.name == 'category':
                le = LabelEncoder()
                X[col] = le.fit_transform(X[col].astype(str))

        # æ¨™æº–åŒ–
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        # KMeansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        kmeans = KMeans(n_clusters=cluster_count, random_state=42)
        clusters = kmeans.fit_predict(X_scaled)

        filtered_df['cluster'] = clusters

        st.markdown(f"#### ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœï¼ˆK={cluster_count}ï¼‰")
        st.write(filtered_df[['ID'] + selected_features + ['cluster']])

        # ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®äººæ•°è¡¨ç¤º
#        st.markdown("#### ã‚¯ãƒ©ã‚¹ã‚¿äººæ•°åˆ†å¸ƒ")
#        cluster_counts = filtered_df['cluster'].value_counts().sort_index()
#        st.bar_chart(cluster_counts)


        # ã‚¯ãƒ©ã‚¹ã‚¿äººæ•°åˆ†å¸ƒã®ä¸‹ã«è¿½åŠ 
        st.markdown("#### ã‚¯ãƒ©ã‚¹ã‚¿å†…å®¹")
    
        num_clusters = filtered_df['cluster'].nunique()
        
        num_features = ['å¹´é½¢', 'SNSåˆ©ç”¨æ™‚é–“', 'å¹³å‡è³¼å…¥å˜ä¾¡']
        cat_features = ['æ€§åˆ¥', 'è·æ¥­', 'è³¼è²·é »åº¦',"é‡è¦è¦–ã™ã‚‹ã“ã¨","è³¼å…¥ã‚¹ã‚¿ã‚¤ãƒ«", 'ã‚­ãƒ£ãƒ©å‚¾å‘']

        rows = []
        
        for c in range(num_clusters):
            cluster_df = filtered_df[filtered_df['cluster'] == c]
            n = len(cluster_df)
            
            row = {"ã‚¯ãƒ©ã‚¹ã‚¿": c, "äººæ•°": n}
            
            # æ•°å€¤ç‰¹å¾´é‡ã®å¹³å‡å€¤
            for f in num_features:
                if f in cluster_df.columns:
                    row[f"{f}å¹³å‡"] = round(cluster_df[f].mean(), 2)
            
            # ã‚«ãƒ†ã‚´ãƒªç‰¹å¾´é‡ã¯æœ€é »å€¤ã¨å‰²åˆã‚’è¡¨ç¤ºï¼ˆä¾‹ï¼‰
            for f in cat_features:
                if f in cluster_df.columns:
                    top_val = cluster_df[f].value_counts(normalize=True).idxmax()
                    top_ratio = cluster_df[f].value_counts(normalize=True).max()
                    row[f"{f}ï¼ˆæœ€å¤šï¼‰"] = f"{top_val} ({top_ratio:.1%})"
            
            rows.append(row)
        
        summary_df = pd.DataFrame(rows)
        
        st.dataframe(summary_df)






        
        # =======================
        # ã‚¯ãƒ©ã‚¹ã‚¿åˆ¥PSMåˆ†æè¡¨ç¤º
        # =======================
        st.markdown("#### ğŸ“Š ã‚¯ãƒ©ã‚¹ã‚¿åˆ¥ Van Westendorp PSMåˆ†æ")

        labels = ['too_cheap', 'cheap', 'expensive', 'too_expensive']
        brands = sorted(set(col.split('_')[0] for col in df.columns if any(lbl in col for lbl in labels)))

        cluster_tabs = st.tabs([f"Cluster {i}" for i in range(cluster_count)])

        for cluster_id, tab in zip(range(cluster_count), cluster_tabs):
            with tab:
                st.markdown(f"##### Cluster {cluster_id} ã®åˆ†æ")
        
                df_cluster = filtered_df[filtered_df['cluster'] == cluster_id]
                results = []  # å„ãƒ–ãƒ©ãƒ³ãƒ‰ã®PSMæŒ‡æ¨™ã‚’ä¿å­˜ã™ã‚‹ãƒªã‚¹ãƒˆ
        
                for brand in brands:
                    brand_cols = [f"{brand}_{lbl}" for lbl in labels if f"{brand}_{lbl}" in df_cluster.columns]
                    df_brand = df_cluster[df_cluster[brand_cols].notnull().any(axis=1)]
        
                    if df_brand.empty:
                        st.warning(f"{brand} ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                        continue
        
                    price_data = {
                        label: df_brand[f"{brand}_{label}"].dropna().astype(int).values
                        for label in labels if f"{brand}_{label}" in df_brand.columns
                    }
        
                    valid_arrays = [arr for arr in price_data.values() if len(arr) > 0]
                    if not valid_arrays:
                        st.warning("æœ‰åŠ¹ãªä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                        continue
        
                    all_prices = np.arange(
                        min(np.concatenate(valid_arrays)),
                        max(np.concatenate(valid_arrays)) + 1000,
                        100
                    )
                    n = len(df_brand)
        
                    cumulative = {
                        'too_cheap': [np.sum(price_data.get('too_cheap', []) >= p) / n for p in all_prices],
                        'cheap': [np.sum(price_data.get('cheap', []) >= p) / n for p in all_prices],
                        'expensive': [np.sum(price_data.get('expensive', []) <= p) / n for p in all_prices],
                        'too_expensive': [np.sum(price_data.get('too_expensive', []) <= p) / n for p in all_prices],
                    }
        
                    opp = find_intersection(cumulative['cheap'], cumulative['expensive'], all_prices)
                    idp = find_intersection(cumulative['too_cheap'], cumulative['too_expensive'], all_prices)
                    pme = find_intersection(cumulative['cheap'], cumulative['too_expensive'], all_prices)
                    pmc = find_intersection(cumulative['expensive'], cumulative['too_cheap'], all_prices)
        
                    # ã‚°ãƒ©ãƒ•ç”Ÿæˆ
                    fig = go.Figure()
                    fig.add_trace(go.Scatter(x=all_prices, y=np.array(cumulative['too_cheap'])*100, name='Too Cheap', line=dict(color='blue')))
                    fig.add_trace(go.Scatter(x=all_prices, y=np.array(cumulative['cheap'])*100, name='Cheap', line=dict(color='green')))
                    fig.add_trace(go.Scatter(x=all_prices, y=np.array(cumulative['expensive'])*100, name='Expensive', line=dict(color='orange')))
                    fig.add_trace(go.Scatter(x=all_prices, y=np.array(cumulative['too_expensive'])*100, name='Too Expensive', line=dict(color='red')))
        
                    for val, name, color in zip(
                        [opp, idp, pme, pmc],
                        ['OPPï¼ˆæœ€é©ï¼‰', 'IDPï¼ˆç„¡é–¢å¿ƒï¼‰', 'PMEï¼ˆä¸Šé™ï¼‰', 'PMCï¼ˆä¸‹é™ï¼‰'],
                        ['purple', 'black', 'magenta', 'cyan']
                    ):
                        if val:
                            fig.add_vline(x=val, line_dash='dash', line_color=color)
                            fig.add_annotation(x=val, y=50, text=name, showarrow=False, textangle=90,
                                               font=dict(color=color, size=12), bgcolor='white')
        
                    fig.update_layout(
                        title=f"{brand} - PSMåˆ†æ",
                        xaxis_title="ä¾¡æ ¼ï¼ˆå††ï¼‰",
                        yaxis_title="ç´¯ç©æ¯”ç‡ï¼ˆ%ï¼‰",
                        height=400,
                        hovermode="x unified",
                        xaxis=dict(tickformat='d')
                    )
        
                    # ---- å…¨ä½“é›†è¨ˆï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚ã¨ï¼‰----
                    col_plot, col_info = st.columns([3, 1])
                    with col_plot:
                        st.plotly_chart(fig, use_container_width=True)
                    with col_info:
                        st.markdown("#### ğŸ‘‡ æŒ‡æ¨™")
                        st.markdown(f"**{brand} ã®è©²å½“äººæ•°ï¼š{df_brand.shape[0]}äºº**")
                        st.write(f"ğŸ“Œ **æœ€é©ä¾¡æ ¼ï¼ˆOPPï¼‰**: {round(opp) if opp else 'è¨ˆç®—ä¸å¯'} å††")
                        st.write(f"ğŸ“Œ **ç„¡é–¢å¿ƒä¾¡æ ¼ï¼ˆIDPï¼‰**: {round(idp) if idp else 'è¨ˆç®—ä¸å¯'} å††")
                        st.write(f"ğŸ“Œ **ä¾¡æ ¼å—å®¹ç¯„å›²ä¸‹é™ï¼ˆPMCï¼‰**: {round(pmc) if pmc else 'è¨ˆç®—ä¸å¯'} å††")
                        st.write(f"ğŸ“Œ **ä¾¡æ ¼å—å®¹ç¯„å›²ä¸Šé™ï¼ˆPMEï¼‰**: {round(pme) if pme else 'è¨ˆç®—ä¸å¯'} å††")
        
                    # æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ 
                    results.append({
                        "ãƒ–ãƒ©ãƒ³ãƒ‰": brand,
                        "è©²å½“äººæ•°": df_brand.shape[0],
                        "æœ€é©ä¾¡æ ¼ï¼ˆOPPï¼‰": round(opp) if opp else None,
                        "ç„¡é–¢å¿ƒä¾¡æ ¼ï¼ˆIDPï¼‰": round(idp) if idp else None,
                        "ä¾¡æ ¼å—å®¹ç¯„å›²ä¸‹é™ï¼ˆPMCï¼‰": round(pmc) if pmc else None,
                        "ä¾¡æ ¼å—å®¹ç¯„å›²ä¸Šé™ï¼ˆPMEï¼‰": round(pme) if pme else None
                    })


                
                # ğŸ”½ å„ã‚¯ãƒ©ã‚¹ã‚¿å†…ã®å…¨ãƒ–ãƒ©ãƒ³ãƒ‰ã¾ã¨ã‚è¡¨ï¼ˆPSMæŒ‡æ¨™ä¸€è¦§ï¼‰
                if results:
                    st.markdown("#### ğŸ“Š ã‚¯ãƒ©ã‚¹ã‚¿å†…ãƒ–ãƒ©ãƒ³ãƒ‰åˆ¥ PSMæŒ‡æ¨™ ä¸€è¦§")
                    df_result = pd.DataFrame(results)
                    st.dataframe(df_result.style.format({col: "{:.0f}" for col in ["OPP", "IDP", "PMC", "PME"]}))
                else:
                    st.info("ã“ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«ã¯æœ‰åŠ¹ãªPSMãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        
        # ---- å…¨ä½“é›†è¨ˆï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‰ï¼‰----
        results_before_filter = []
        for brand in brands:
            brand_cols = [f"{brand}_{lbl}" for lbl in labels if f"{brand}_{lbl}" in df.columns]
            df_brand = df[df[brand_cols].notnull().any(axis=1)]
            if df_brand.empty:
                continue
        
            price_data = {
                label: df_brand[f"{brand}_{label}"].dropna().astype(int).values
                for label in labels if f"{brand}_{label}" in df_brand.columns
            }
        
            valid_arrays = [arr for arr in price_data.values() if len(arr) > 0]
            if not valid_arrays:
                continue
        
            all_prices = np.arange(
                min(np.concatenate(valid_arrays)),
                max(np.concatenate(valid_arrays)) + 1000,
                100
            )
            n = len(df_brand)
        
            cumulative = {
                'too_cheap': [np.sum(price_data.get('too_cheap', []) >= p) / n for p in all_prices],
                'cheap': [np.sum(price_data.get('cheap', []) >= p) / n for p in all_prices],
                'expensive': [np.sum(price_data.get('expensive', []) <= p) / n for p in all_prices],
                'too_expensive': [np.sum(price_data.get('too_expensive', []) <= p) / n for p in all_prices],
            }
        
            opp = find_intersection(cumulative['cheap'], cumulative['expensive'], all_prices)
            idp = find_intersection(cumulative['too_cheap'], cumulative['too_expensive'], all_prices)
            pme = find_intersection(cumulative['cheap'], cumulative['too_expensive'], all_prices)
            pmc = find_intersection(cumulative['expensive'], cumulative['too_cheap'], all_prices)
        
            results_before_filter.append({
                "ãƒ–ãƒ©ãƒ³ãƒ‰": brand,
                "OPP": opp,
                "IDP": idp,
                "PMC": pmc,
                "PME": pme
            })
        
        # ---- è¡¨ç¤ºéƒ¨ ----
        st.markdown("---")
        with st.expander("ğŸ“‹ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‰ ãƒ–ãƒ©ãƒ³ãƒ‰åˆ¥ PSM æŒ‡æ¨™ä¸€è¦§ï¼ˆå…¨ä½“é›†è¨ˆï¼‰", expanded=False):
            st.markdown(f"**å…¨ä½“èª¿æŸ»äººæ•°ï¼š{len(df)}äºº**")
            summary_df_before = pd.DataFrame(results_before_filter)
            st.dataframe(summary_df_before.style.format({col: "{:.0f}" for col in summary_df_before.columns if col != "ãƒ–ãƒ©ãƒ³ãƒ‰"}))
        


else:
    st.info("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

# %%

# %% [markdown]
# å‰ã®æŒ‡æ¨™ã®è¡¨ç¤ºã€€OK
#

# %% [markdown] jupyter={"source_hidden": true}
# import streamlit as st
# import pandas as pd
# import numpy as np
# from sklearn.preprocessing import StandardScaler
# from sklearn.cluster import KMeans
# import plotly.graph_objects as go
# from scipy.interpolate import interp1d
#
# st.set_page_config(layout="wide")
# st.title("ğŸ’´ Van Westendorp PSM + ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æã‚¢ãƒ—ãƒª")
#
# @st.cache_data
# def load_data(uploaded_file):
#     return pd.read_csv(uploaded_file)
#
# def find_intersection(y1, y2, x):
#     diff = np.array(y1) - np.array(y2)
#     sign_change = np.where(np.diff(np.sign(diff)) != 0)[0]
#     if len(sign_change) == 0:
#         return None
#     i = sign_change[0]
#     try:
#         f = interp1d(diff[i:i+2], x[i:i+2])
#         return float(f(0))
#     except Exception:
#         return None
#
# uploaded_file = st.file_uploader("ğŸ“‚ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"])
#
# if uploaded_file is not None:
#     df = load_data(uploaded_file)
#     st.markdown("#### ğŸ” çµã‚Šè¾¼ã¿ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")
#     col1, col2, col3 = st.columns(3)
#     
#     with col1:
#         if 'å¹´é½¢' in df.columns:
#             min_age = int(df['å¹´é½¢'].min())
#             max_age = int(df['å¹´é½¢'].max())
#             selected_age_range = st.slider("ğŸ” å¹´é½¢ç¯„å›²", min_age, max_age, (min_age, max_age))
#         else:
#             selected_age_range = None
#     
#         # æ€§åˆ¥ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
#         if 'æ€§åˆ¥' in df.columns:
#             gender_options = df['æ€§åˆ¥'].dropna().unique().tolist()
#             if 'selected_gender' not in st.session_state:
#                 st.session_state.selected_gender = gender_options
#             selected_gender = st.multiselect(
#                 "ğŸ” æ€§åˆ¥", options=gender_options, default=st.session_state.selected_gender
#             )
#             st.session_state.selected_gender = selected_gender
#         else:
#             selected_gender = None
#     
#         # è·æ¥­ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
#         if 'è·æ¥­' in df.columns:
#             job_options = df['è·æ¥­'].dropna().unique().tolist()
#             if 'selected_jobs' not in st.session_state:
#                 st.session_state.selected_jobs = job_options
#             selected_jobs = st.multiselect(
#                 "ğŸ” è·æ¥­", options=job_options, default=st.session_state.selected_jobs
#             )
#             st.session_state.selected_jobs = selected_jobs
#         else:
#             selected_jobs = None
#     
#         if 'å¹³å‡è³¼å…¥å˜ä¾¡' in df.columns:
#             min_price = int(df['å¹³å‡è³¼å…¥å˜ä¾¡'].min())
#             max_price = int(df['å¹³å‡è³¼å…¥å˜ä¾¡'].max())
#             selected_average_bands = st.slider("ğŸ” å¹³å‡è³¼å…¥å˜ä¾¡", min_price, max_price, (min_price, max_price))
#         else:
#             selected_average_bands = None
#     
#         if 'SNSåˆ©ç”¨æ™‚é–“' in df.columns:
#             min_sns = int(df['SNSåˆ©ç”¨æ™‚é–“'].min())
#             max_sns = int(df['SNSåˆ©ç”¨æ™‚é–“'].max())
#             selected_sns = st.slider("ğŸ” SNSåˆ©ç”¨æ™‚é–“", min_sns, max_sns, (min_sns, max_sns))
#         else:
#             selected_sns = None
#     
#     with col2:
#         # ã‚­ãƒ£ãƒ©å‚¾å‘ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
#         if 'ã‚­ãƒ£ãƒ©å‚¾å‘' in df.columns:
#             char_options = df['ã‚­ãƒ£ãƒ©å‚¾å‘'].dropna().unique().tolist()
#             if 'selected_character' not in st.session_state:
#                 st.session_state.selected_character = char_options
#             selected_character = st.multiselect(
#                 "ğŸ” ã‚­ãƒ£ãƒ©å‚¾å‘", options=char_options, default=st.session_state.selected_character
#             )
#             st.session_state.selected_character = selected_character
#         else:
#             selected_character = None
#     
#         # é‡è¦è¦–ã™ã‚‹ã“ã¨1 ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
#         if 'é‡è¦è¦–ã™ã‚‹ã“ã¨' in df.columns:
#             imp_options = df['é‡è¦è¦–ã™ã‚‹ã“ã¨'].dropna().unique().tolist()
#             if 'selected_importance' not in st.session_state:
#                 st.session_state.selected_importance = imp_options
#             selected_importance = st.multiselect(
#                 "ğŸ” é‡è¦è¦–ã™ã‚‹ã“ã¨", options=imp_options, default=st.session_state.selected_importance
#             )
#             st.session_state.selected_importance = selected_importance
#         else:
#             selected_importance = None
#     
#         # è³¼è²·é »åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
#         if 'è³¼è²·é »åº¦' in df.columns:
#             freq_options = df['è³¼è²·é »åº¦'].dropna().unique().tolist()
#             if 'selected_frequency' not in st.session_state:
#                 st.session_state.selected_frequency = freq_options
#             selected_frequency = st.multiselect(
#                 "ğŸ” è³¼è²·é »åº¦", options=freq_options, default=st.session_state.selected_frequency
#             )
#             st.session_state.selected_frequency = selected_frequency
#         else:
#             selected_frequency = None
#     
#     with col3:
#         if 'è³¼å…¥ã‚¹ã‚¿ã‚¤ãƒ«' in df.columns:
#             style_options = df['è³¼å…¥ã‚¹ã‚¿ã‚¤ãƒ«'].dropna().unique().tolist()
#             st.markdown("ğŸ” è³¼å…¥ã‚¹ã‚¿ã‚¤ãƒ«")
#     
#             if "selected_style" not in st.session_state:
#                 st.session_state.selected_style = {s: True for s in style_options}
#     
#             colA, colB = st.columns(2)
#             with colA:
#                 if st.button("âœ… å…¨ã¦é¸æŠ"):
#                     for s in style_options:
#                         st.session_state.selected_style[s] = True
#             with colB:
#                 if st.button("âŒ å…¨ã¦è§£é™¤"):
#                     for s in style_options:
#                         st.session_state.selected_style[s] = False
#     
#             selected_style = []
#             for s in style_options:
#                 checked = st.checkbox(s, value=st.session_state.selected_style[s])
#                 st.session_state.selected_style[s] = checked
#                 if checked:
#                     selected_style.append(s)
#         else:
#             selected_style = None
#             
#     # ================
#     # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†
#     # ================
#     filtered_df = df.copy()
#     if selected_age_range:
#         filtered_df = filtered_df[filtered_df['å¹´é½¢'].between(*selected_age_range)]
#     if selected_gender:
#         filtered_df = filtered_df[filtered_df['æ€§åˆ¥'].isin(selected_gender)]
#     if selected_jobs:
#         filtered_df = filtered_df[filtered_df['è·æ¥­'].isin(selected_jobs)]
#     if selected_character:
#         filtered_df = filtered_df[filtered_df['ã‚­ãƒ£ãƒ©å‚¾å‘'].isin(selected_character)]
#     if selected_frequency:
#         filtered_df = filtered_df[filtered_df['è³¼è²·é »åº¦'].isin(selected_frequency)]
#     if selected_style:
#         filtered_df = filtered_df[filtered_df['è³¼å…¥ã‚¹ã‚¿ã‚¤ãƒ«'].isin(selected_style)]
#     if selected_importance:
#         filtered_df = filtered_df[filtered_df['é‡è¦è¦–ã™ã‚‹ã“ã¨'].isin(selected_importance)]
#     if selected_sns:
#         filtered_df = filtered_df[filtered_df['SNSåˆ©ç”¨æ™‚é–“'].between(*selected_sns)]
#     if selected_average_bands:
#         filtered_df = filtered_df[filtered_df['å¹³å‡è³¼å…¥å˜ä¾¡'].between(*selected_average_bands)]
#
#     st.markdown(f"### ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œã®å¯¾è±¡è€…æ•°: {len(filtered_df)} äºº")
#
#     # ======================
#     # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
#     # ======================
#     st.markdown("#### ğŸ§© ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°è¨­å®š")
#
#     # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã«ä½¿ã†ç‰¹å¾´é‡é¸æŠUIï¼ˆã‚«ãƒ†ã‚´ãƒªã¯ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼‰
#     candidate_features = ['å¹´é½¢', 'æ€§åˆ¥','è·æ¥­','è³¼è²·é »åº¦','å¹³å‡è³¼å…¥å˜ä¾¡', 'è³¼å…¥ã‚¹ã‚¿ã‚¤ãƒ«', 'é‡è¦è¦–ã™ã‚‹ã“ã¨']
#     selected_features = st.multiselect("ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã«ä½¿ã†å±æ€§ã‚’é¸æŠã—ã¦ãã ã•ã„", candidate_features, default=candidate_features)
#
#     if len(selected_features) == 0:
#         st.warning("å°‘ãªãã¨ã‚‚1ã¤ä»¥ä¸Šã®ç‰¹å¾´é‡ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
#     else:
#         cluster_count = st.slider("ã‚¯ãƒ©ã‚¹ã‚¿æ•° (K)", 2, 10, 3)
#
#         # å‰å‡¦ç†ï¼šã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã¯label encodingï¼ˆç°¡æ˜“ç‰ˆï¼‰
#         from sklearn.preprocessing import LabelEncoder
#         X = filtered_df[selected_features].copy()
#
#         for col in X.columns:
#             if X[col].dtype == 'object' or X[col].dtype.name == 'category':
#                 le = LabelEncoder()
#                 X[col] = le.fit_transform(X[col].astype(str))
#
#         # æ¨™æº–åŒ–
#         scaler = StandardScaler()
#         X_scaled = scaler.fit_transform(X)
#
#         # KMeansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
#         kmeans = KMeans(n_clusters=cluster_count, random_state=42)
#         clusters = kmeans.fit_predict(X_scaled)
#
#         filtered_df['cluster'] = clusters
#
#         st.markdown(f"### ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœï¼ˆK={cluster_count}ï¼‰")
#         st.write(filtered_df[['ID'] + selected_features + ['cluster']])
#
#         # ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®äººæ•°è¡¨ç¤º
# #        st.markdown("#### ã‚¯ãƒ©ã‚¹ã‚¿äººæ•°åˆ†å¸ƒ")
# #        cluster_counts = filtered_df['cluster'].value_counts().sort_index()
# #        st.bar_chart(cluster_counts)
#
#
#         # ã‚¯ãƒ©ã‚¹ã‚¿äººæ•°åˆ†å¸ƒã®ä¸‹ã«è¿½åŠ 
#         st.markdown("#### ã‚¯ãƒ©ã‚¹ã‚¿å†…å®¹")
#     
#         num_clusters = filtered_df['cluster'].nunique()
#         
#         num_features = ['å¹´é½¢', 'SNSåˆ©ç”¨æ™‚é–“', 'å¹³å‡è³¼å…¥å˜ä¾¡']
#         cat_features = ['æ€§åˆ¥', 'è·æ¥­', 'è³¼è²·é »åº¦',"é‡è¦è¦–ã™ã‚‹ã“ã¨","è³¼å…¥ã‚¹ã‚¿ã‚¤ãƒ«", 'ã‚­ãƒ£ãƒ©å‚¾å‘']
#
#         rows = []
#         
#         for c in range(num_clusters):
#             cluster_df = filtered_df[filtered_df['cluster'] == c]
#             n = len(cluster_df)
#             
#             row = {"ã‚¯ãƒ©ã‚¹ã‚¿": c, "äººæ•°": n}
#             
#             # æ•°å€¤ç‰¹å¾´é‡ã®å¹³å‡å€¤
#             for f in num_features:
#                 if f in cluster_df.columns:
#                     row[f"{f}å¹³å‡"] = round(cluster_df[f].mean(), 2)
#             
#             # ã‚«ãƒ†ã‚´ãƒªç‰¹å¾´é‡ã¯æœ€é »å€¤ã¨å‰²åˆã‚’è¡¨ç¤ºï¼ˆä¾‹ï¼‰
#             for f in cat_features:
#                 if f in cluster_df.columns:
#                     top_val = cluster_df[f].value_counts(normalize=True).idxmax()
#                     top_ratio = cluster_df[f].value_counts(normalize=True).max()
#                     row[f"{f}ï¼ˆæœ€å¤šï¼‰"] = f"{top_val} ({top_ratio:.1%})"
#             
#             rows.append(row)
#         
#         summary_df = pd.DataFrame(rows)
#         
#         st.dataframe(summary_df)
#
#
#
#
#
#
#         
#         # =======================
#         # ã‚¯ãƒ©ã‚¹ã‚¿åˆ¥PSMåˆ†æè¡¨ç¤º
#         # =======================
#         st.markdown("#### ğŸ“Š ã‚¯ãƒ©ã‚¹ã‚¿åˆ¥ Van Westendorp PSMåˆ†æ")
#
#         labels = ['too_cheap', 'cheap', 'expensive', 'too_expensive']
#         brands = sorted(set(col.split('_')[0] for col in df.columns if any(lbl in col for lbl in labels)))
#
#         cluster_tabs = st.tabs([f"Cluster {i}" for i in range(cluster_count)])
#
#         for cluster_id, tab in zip(range(cluster_count), cluster_tabs):
#             with tab:
#                 st.markdown(f"##### Cluster {cluster_id} ã®åˆ†æ")
#
#                 df_cluster = filtered_df[filtered_df['cluster'] == cluster_id]
#
#                 for brand in brands:
#                     brand_cols = [f"{brand}_{lbl}" for lbl in labels if f"{brand}_{lbl}" in df_cluster.columns]
#                     df_brand = df_cluster[df_cluster[brand_cols].notnull().any(axis=1)]
#
#                     if df_brand.empty:
#                         st.warning(f"{brand} ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
#                         continue
#
#                     price_data = {
#                         label: df_brand[f"{brand}_{label}"].dropna().astype(int).values
#                         for label in labels if f"{brand}_{label}" in df_brand.columns
#                     }
#
#                     valid_arrays = [arr for arr in price_data.values() if len(arr) > 0]
#                     if not valid_arrays:
#                         st.warning("æœ‰åŠ¹ãªä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
#                         continue
#
#                     all_prices = np.arange(
#                         min(np.concatenate(valid_arrays)),
#                         max(np.concatenate(valid_arrays)) + 1000,
#                         100
#                     )
#                     n = len(df_brand)
#
#                     cumulative = {
#                         'too_cheap': [np.sum(price_data.get('too_cheap', []) >= p) / n for p in all_prices],
#                         'cheap': [np.sum(price_data.get('cheap', []) >= p) / n for p in all_prices],
#                         'expensive': [np.sum(price_data.get('expensive', []) <= p) / n for p in all_prices],
#                         'too_expensive': [np.sum(price_data.get('too_expensive', []) <= p) / n for p in all_prices],
#                     }
#
#                     opp = find_intersection(cumulative['cheap'], cumulative['expensive'], all_prices)
#                     idp = find_intersection(cumulative['too_cheap'], cumulative['too_expensive'], all_prices)
#                     pme = find_intersection(cumulative['cheap'], cumulative['too_expensive'], all_prices)
#                     pmc = find_intersection(cumulative['expensive'], cumulative['too_cheap'], all_prices)
#
#                     fig = go.Figure()
#                                         
#                     fig.add_trace(go.Scatter(x=all_prices, y=np.array(cumulative['too_cheap'])*100, name='Too Cheap', line=dict(color='blue')))
#                     fig.add_trace(go.Scatter(x=all_prices, y=np.array(cumulative['cheap'])*100, name='Cheap', line=dict(color='green')))
#                     fig.add_trace(go.Scatter(x=all_prices, y=np.array(cumulative['expensive'])*100, name='Expensive', line=dict(color='orange')))
#                     fig.add_trace(go.Scatter(x=all_prices, y=np.array(cumulative['too_expensive'])*100, name='Too Expensive', line=dict(color='red')))
#
#                     # è£œåŠ©ç·šã¨ãƒ©ãƒ™ãƒ«è¡¨ç¤º
#                     for val, name, color in zip(
#                         [opp, idp, pme, pmc],
#                         ['OPPï¼ˆæœ€é©ï¼‰', 'IDPï¼ˆç„¡é–¢å¿ƒï¼‰', 'PMEï¼ˆä¸Šé™ï¼‰', 'PMCï¼ˆä¸‹é™ï¼‰'],
#                         ['purple', 'black', 'magenta', 'cyan']
#                     ):
#                         if val:
#                             fig.add_vline(x=val, line_dash='dash', line_color=color)
#                             fig.add_annotation(x=val, y=50, text=name, showarrow=False, textangle=90,
#                                                font=dict(color=color, size=12), bgcolor='white')
#
#
#
#                     # ... add traces and annotations ...
#                     
#                     fig.update_layout(
#                         title=f"{brand} - PSMåˆ†æ",
#                         xaxis_title="ä¾¡æ ¼ï¼ˆå††ï¼‰",
#                         yaxis_title="ç´¯ç©æ¯”ç‡ï¼ˆ%ï¼‰",
#                         height=400,
#                         hovermode="x unified",
#                         xaxis=dict(tickformat='d')
#                     )
#                     
#                     # ã‚°ãƒ©ãƒ•ã¨æŒ‡æ¨™ã‚’æ¨ªä¸¦ã³ã«è¡¨ç¤º
#                     col_plot, col_info = st.columns([3, 1])
#                     with col_plot:
#                         st.plotly_chart(fig, use_container_width=True)
#                     with col_info:
#                         st.markdown("#### ğŸ‘‡ æŒ‡æ¨™")
#                         st.markdown(f"**{brand} ã®è©²å½“äººæ•°ï¼š{df_brand.shape[0]}äºº**")
#                         st.write(f"ğŸ“Œ **æœ€é©ä¾¡æ ¼ï¼ˆOPPï¼‰**: {round(opp) if opp else 'è¨ˆç®—ä¸å¯'} å††")
#                         st.write(f"ğŸ“Œ **ç„¡é–¢å¿ƒä¾¡æ ¼ï¼ˆIDPï¼‰**: {round(idp) if idp else 'è¨ˆç®—ä¸å¯'} å††")
#                         st.write(f"ğŸ“Œ **ä¾¡æ ¼å—å®¹ç¯„å›²ä¸‹é™ï¼ˆPMCï¼‰**: {round(pmc) if pmc else 'è¨ˆç®—ä¸å¯'} å††")
#                         st.write(f"ğŸ“Œ **ä¾¡æ ¼å—å®¹ç¯„å›²ä¸Šé™ï¼ˆPMEï¼‰**: {round(pme) if pme else 'è¨ˆç®—ä¸å¯'} å††")
#
#
#
#
#         
#         # ---- å…¨ä½“é›†è¨ˆï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‰ï¼‰----
#         results_before_filter = []
#         for brand in brands:
#             brand_cols = [f"{brand}_{lbl}" for lbl in labels if f"{brand}_{lbl}" in df.columns]
#             df_brand = df[df[brand_cols].notnull().any(axis=1)]
#             if df_brand.empty:
#                 continue
#         
#             price_data = {
#                 label: df_brand[f"{brand}_{label}"].dropna().astype(int).values
#                 for label in labels if f"{brand}_{label}" in df_brand.columns
#             }
#         
#             valid_arrays = [arr for arr in price_data.values() if len(arr) > 0]
#             if not valid_arrays:
#                 continue
#         
#             all_prices = np.arange(
#                 min(np.concatenate(valid_arrays)),
#                 max(np.concatenate(valid_arrays)) + 1000,
#                 100
#             )
#             n = len(df_brand)
#         
#             cumulative = {
#                 'too_cheap': [np.sum(price_data.get('too_cheap', []) >= p) / n for p in all_prices],
#                 'cheap': [np.sum(price_data.get('cheap', []) >= p) / n for p in all_prices],
#                 'expensive': [np.sum(price_data.get('expensive', []) <= p) / n for p in all_prices],
#                 'too_expensive': [np.sum(price_data.get('too_expensive', []) <= p) / n for p in all_prices],
#             }
#         
#             opp = find_intersection(cumulative['cheap'], cumulative['expensive'], all_prices)
#             idp = find_intersection(cumulative['too_cheap'], cumulative['too_expensive'], all_prices)
#             pme = find_intersection(cumulative['cheap'], cumulative['too_expensive'], all_prices)
#             pmc = find_intersection(cumulative['expensive'], cumulative['too_cheap'], all_prices)
#         
#             results_before_filter.append({
#                 "ãƒ–ãƒ©ãƒ³ãƒ‰": brand,
#                 "OPP": opp,
#                 "IDP": idp,
#                 "PMC": pmc,
#                 "PME": pme
#             })
#         
#         # ---- è¡¨ç¤ºéƒ¨ ----
#         st.markdown("---")
#         with st.expander("ğŸ“‹ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‰ ãƒ–ãƒ©ãƒ³ãƒ‰åˆ¥ PSM æŒ‡æ¨™ä¸€è¦§ï¼ˆå…¨ä½“é›†è¨ˆï¼‰", expanded=False):
#             st.markdown(f"**å…¨ä½“èª¿æŸ»äººæ•°ï¼š{len(df)}äºº**")
#             summary_df_before = pd.DataFrame(results_before_filter)
#             st.dataframe(summary_df_before.style.format({col: "{:.0f}" for col in summary_df_before.columns if col != "ãƒ–ãƒ©ãƒ³ãƒ‰"}))
#         
#
#
# else:
#     st.info("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")


# %%

# %% [markdown]
# ã‚¤ãƒã‚¤ãƒ

# %% [markdown] jupyter={"source_hidden": true}
# import streamlit as st
# import pandas as pd
# import numpy as np
# from sklearn.preprocessing import StandardScaler
# from sklearn.cluster import KMeans
# import plotly.graph_objects as go
# from scipy.interpolate import interp1d
#
# st.set_page_config(layout="wide")
# st.title("ğŸ’´ Van Westendorp PSM + ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æã‚¢ãƒ—ãƒª")
#
# @st.cache_data
# def load_data(uploaded_file):
#     return pd.read_csv(uploaded_file)
#
# def find_intersection(y1, y2, x):
#     diff = np.array(y1) - np.array(y2)
#     sign_change = np.where(np.diff(np.sign(diff)) != 0)[0]
#     if len(sign_change) == 0:
#         return None
#     i = sign_change[0]
#     try:
#         f = interp1d(diff[i:i+2], x[i:i+2])
#         return float(f(0))
#     except Exception:
#         return None
#
# uploaded_file = st.file_uploader("ğŸ“‚ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"])
#
# if uploaded_file is not None:
#     df = load_data(uploaded_file)
#
#     st.markdown("#### ğŸ” çµã‚Šè¾¼ã¿ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")
#     col1, col2, col3 = st.columns(3)
#
#     with col1:
#         if 'å¹´é½¢' in df.columns:
#             min_age = int(df['å¹´é½¢'].min())
#             max_age = int(df['å¹´é½¢'].max())
#             selected_age_range = st.slider("å¹´é½¢ç¯„å›²", min_age, max_age, (min_age, max_age))
#         else:
#             selected_age_range = None
#
#         if 'æ€§åˆ¥' in df.columns:
#             gender_options = df['æ€§åˆ¥'].dropna().unique().tolist()
#             selected_gender = st.multiselect("æ€§åˆ¥", gender_options, default=gender_options)
#         else:
#             selected_gender = None
#
#
#         if 'é‡è¦è¦–ã™ã‚‹ã“ã¨' in df.columns:
#             imp_options = df['é‡è¦è¦–ã™ã‚‹ã“ã¨'].dropna().unique().tolist()
#             selected_importance = st.multiselect("é‡è¦è¦–ã™ã‚‹ã“ã¨", imp_options, default=imp_options)
#         else:
#             selected_importance = None
#
#     
#     with col2:
#         if 'è³¼å…¥ã‚¹ã‚¿ã‚¤ãƒ«' in df.columns:
#             style_options = df['è³¼å…¥ã‚¹ã‚¿ã‚¤ãƒ«'].dropna().unique().tolist()
#             st.markdown("ğŸ” è³¼å…¥ã‚¹ã‚¿ã‚¤ãƒ«")
#         
#             if "selected_style" not in st.session_state:
#                 st.session_state.selected_style = {s: True for s in style_options}
#         
#             colA, colB = st.columns(2)
#             with colA:
#                 if st.button("âœ… å…¨ã¦é¸æŠ", key="style_select_all"):
#                     for s in style_options:
#                         st.session_state.selected_style[s] = True
#             with colB:
#                 if st.button("âŒ å…¨ã¦è§£é™¤", key="style_deselect_all"):  # ğŸ” keyã‚’å¤‰æ›´
#                     for s in style_options:
#                         st.session_state.selected_style[s] = False
#         
#             selected_style = []
#             for s in style_options:
#                 checked = st.checkbox(s, value=st.session_state.selected_style[s])
#                 st.session_state.selected_style[s] = checked
#                 if checked:
#                     selected_style.append(s)
#         else:
#             selected_style = None
#         
#         with col3:
#         
#             if 'ç”Ÿæ´»ã§å¤§åˆ‡ãªã“ã¨' in df.columns:
#                 life_options = df['ç”Ÿæ´»ã§å¤§åˆ‡ãªã“ã¨'].dropna().unique().tolist()
#                 st.markdown("ğŸ” ç”Ÿæ´»ã§å¤§åˆ‡ãªã“ã¨")
#         
#                 if "selected_life" not in st.session_state:
#                     st.session_state.selected_life = {s: True for s in life_options}
#         
#                 colA, colB = st.columns(2)
#                 with colA:
#                     if st.button("âœ… å…¨ã¦é¸æŠ", key="life_select_all"):
#                         for s in life_options:
#                             st.session_state.selected_life[s] = True
#                 with colB:
#                     if st.button("âŒ å…¨ã¦è§£é™¤", key="life_deselect_all"):  # ğŸ” keyã‚’å¤‰æ›´
#                         for s in life_options:  # ğŸ” ss â†’ s ã«ä¿®æ­£
#                             st.session_state.selected_life[s] = False
#         
#                 selected_life = []
#                 for s in life_options:
#                     checked = st.checkbox(s, value=st.session_state.selected_life[s])
#                     st.session_state.selected_life[s] = checked
#                     if checked:
#                         selected_life.append(s)
#             else:
#                 selected_life = None
#
#
#             
#     # ================
#     # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†
#     # ================
#     filtered_df = df.copy()
#     if selected_age_range:
#         filtered_df = filtered_df[filtered_df['å¹´é½¢'].between(*selected_age_range)]
#     if selected_gender:
#         filtered_df = filtered_df[filtered_df['æ€§åˆ¥'].isin(selected_gender)]
#     if selected_life:
#         filtered_df = filtered_df[filtered_df['ç”Ÿæ´»ã§å¤§åˆ‡ãªã“ã¨'].isin(selected_life)]
#     if selected_style:
#         filtered_df = filtered_df[filtered_df['è³¼å…¥ã‚¹ã‚¿ã‚¤ãƒ«'].isin(selected_style)]
#     if selected_importance:
#         filtered_df = filtered_df[filtered_df['é‡è¦è¦–ã™ã‚‹ã“ã¨'].isin(selected_importance)]
#
#     st.markdown(f"### ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œã®å¯¾è±¡è€…æ•°: {len(filtered_df)} äºº")
#
#     # ======================
#     # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
#     # ======================
#     st.markdown("#### ğŸ§© ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°è¨­å®š")
#
#     # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã«ä½¿ã†ç‰¹å¾´é‡é¸æŠUIï¼ˆã‚«ãƒ†ã‚´ãƒªã¯ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼‰
#     candidate_features = ['å¹´é½¢', 'æ€§åˆ¥', 'ç”Ÿæ´»ã§å¤§åˆ‡ãªã“ã¨', 'è³¼å…¥ã‚¹ã‚¿ã‚¤ãƒ«', 'é‡è¦è¦–ã™ã‚‹ã“ã¨']
#     selected_features = st.multiselect("ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã«ä½¿ã†å±æ€§ã‚’é¸æŠã—ã¦ãã ã•ã„", candidate_features, default=['å¹´é½¢', 'æ€§åˆ¥',  'ç”Ÿæ´»ã§å¤§åˆ‡ãªã“ã¨', 'è³¼å…¥ã‚¹ã‚¿ã‚¤ãƒ«', 'é‡è¦è¦–ã™ã‚‹ã“ã¨'])
#
#     if len(selected_features) == 0:
#         st.warning("å°‘ãªãã¨ã‚‚1ã¤ä»¥ä¸Šã®ç‰¹å¾´é‡ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
#     else:
#         cluster_count = st.slider("ã‚¯ãƒ©ã‚¹ã‚¿æ•° (K)", 2, 10, 3)
#
#         # å‰å‡¦ç†ï¼šã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã¯label encodingï¼ˆç°¡æ˜“ç‰ˆï¼‰
#         from sklearn.preprocessing import LabelEncoder
#         X = filtered_df[selected_features].copy()
#
#         for col in X.columns:
#             if X[col].dtype == 'object' or X[col].dtype.name == 'category':
#                 le = LabelEncoder()
#                 X[col] = le.fit_transform(X[col].astype(str))
#
#         # æ¨™æº–åŒ–
#         scaler = StandardScaler()
#         X_scaled = scaler.fit_transform(X)
#
#         # KMeansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
#         kmeans = KMeans(n_clusters=cluster_count, random_state=42)
#         clusters = kmeans.fit_predict(X_scaled)
#
#         filtered_df['cluster'] = clusters
#
#         st.markdown(f"### ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœï¼ˆK={cluster_count}ï¼‰")
#         st.write(filtered_df[['ID'] + selected_features + ['cluster']])
#
#         # ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®äººæ•°è¡¨ç¤º
# #        st.markdown("#### ã‚¯ãƒ©ã‚¹ã‚¿äººæ•°åˆ†å¸ƒ")
# #        cluster_counts = filtered_df['cluster'].value_counts().sort_index()
# #        st.bar_chart(cluster_counts)
#
#
#         # ã‚¯ãƒ©ã‚¹ã‚¿äººæ•°åˆ†å¸ƒã®ä¸‹ã«è¿½åŠ 
#         st.markdown("#### ã‚¯ãƒ©ã‚¹ã‚¿å†…å®¹")
#     
#         num_clusters = filtered_df['cluster'].nunique()
#         
#         num_features = ['å¹´é½¢', 'SNSåˆ©ç”¨æ™‚é–“', 'å¹³å‡è³¼å…¥å˜ä¾¡']
#         cat_features = ['æ€§åˆ¥', 'è·æ¥­', 'è³¼è²·é »åº¦', 'ã‚­ãƒ£ãƒ©å‚¾å‘',"é‡è¦è¦–ã™ã‚‹ã“ã¨1","è³¼å…¥ã‚¹ã‚¿ã‚¤ãƒ«1"]
#
#         rows = []
#         
#         for c in range(num_clusters):
#             cluster_df = filtered_df[filtered_df['cluster'] == c]
#             n = len(cluster_df)
#             
#             row = {"ã‚¯ãƒ©ã‚¹ã‚¿": c, "äººæ•°": n}
#             
#             # æ•°å€¤ç‰¹å¾´é‡ã®å¹³å‡å€¤
#             for f in num_features:
#                 if f in cluster_df.columns:
#                     row[f"{f}å¹³å‡"] = round(cluster_df[f].mean(), 2)
#             
#             # ã‚«ãƒ†ã‚´ãƒªç‰¹å¾´é‡ã¯æœ€é »å€¤ã¨å‰²åˆã‚’è¡¨ç¤ºï¼ˆä¾‹ï¼‰
#             for f in cat_features:
#                 if f in cluster_df.columns:
#                     top_val = cluster_df[f].value_counts(normalize=True).idxmax()
#                     top_ratio = cluster_df[f].value_counts(normalize=True).max()
#                     row[f"{f}ï¼ˆæœ€å¤šï¼‰"] = f"{top_val} ({top_ratio:.1%})"
#             
#             rows.append(row)
#         
#         summary_df = pd.DataFrame(rows)
#         
#         st.dataframe(summary_df)
#
#
#
#
#
#
#         
#         # =======================
#         # ã‚¯ãƒ©ã‚¹ã‚¿åˆ¥PSMåˆ†æè¡¨ç¤º
#         # =======================
#         st.markdown("#### ğŸ“Š ã‚¯ãƒ©ã‚¹ã‚¿åˆ¥ Van Westendorp PSMåˆ†æ")
#
#         labels = ['too_cheap', 'cheap', 'expensive', 'too_expensive']
#         brands = sorted(set(col.split('_')[0] for col in df.columns if any(lbl in col for lbl in labels)))
#
#         cluster_tabs = st.tabs([f"Cluster {i}" for i in range(cluster_count)])
#
#         for cluster_id, tab in zip(range(cluster_count), cluster_tabs):
#             with tab:
#                 st.markdown(f"##### Cluster {cluster_id} ã®åˆ†æ")
#
#                 df_cluster = filtered_df[filtered_df['cluster'] == cluster_id]
#
#                 for brand in brands:
#                     brand_cols = [f"{brand}_{lbl}" for lbl in labels if f"{brand}_{lbl}" in df_cluster.columns]
#                     df_brand = df_cluster[df_cluster[brand_cols].notnull().any(axis=1)]
#
#                     if df_brand.empty:
#                         st.warning(f"{brand} ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
#                         continue
#
#                     price_data = {
#                         label: df_brand[f"{brand}_{label}"].dropna().astype(int).values
#                         for label in labels if f"{brand}_{label}" in df_brand.columns
#                     }
#
#                     valid_arrays = [arr for arr in price_data.values() if len(arr) > 0]
#                     if not valid_arrays:
#                         st.warning("æœ‰åŠ¹ãªä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
#                         continue
#
#                     all_prices = np.arange(
#                         min(np.concatenate(valid_arrays)),
#                         max(np.concatenate(valid_arrays)) + 1000,
#                         100
#                     )
#                     n = len(df_brand)
#
#                     cumulative = {
#                         'too_cheap': [np.sum(price_data.get('too_cheap', []) >= p) / n for p in all_prices],
#                         'cheap': [np.sum(price_data.get('cheap', []) >= p) / n for p in all_prices],
#                         'expensive': [np.sum(price_data.get('expensive', []) <= p) / n for p in all_prices],
#                         'too_expensive': [np.sum(price_data.get('too_expensive', []) <= p) / n for p in all_prices],
#                     }
#
#                     opp = find_intersection(cumulative['cheap'], cumulative['expensive'], all_prices)
#                     idp = find_intersection(cumulative['too_cheap'], cumulative['too_expensive'], all_prices)
#                     pme = find_intersection(cumulative['cheap'], cumulative['too_expensive'], all_prices)
#                     pmc = find_intersection(cumulative['expensive'], cumulative['too_cheap'], all_prices)
#
#                     fig = go.Figure()
#                     fig.add_trace(go.Scatter(x=all_prices, y=np.array(cumulative['too_cheap'])*100, name='Too Cheap', line=dict(color='blue')))
#                     fig.add_trace(go.Scatter(x=all_prices, y=np.array(cumulative['cheap'])*100, name='Cheap', line=dict(color='green')))
#                     fig.add_trace(go.Scatter(x=all_prices, y=np.array(cumulative['expensive'])*100, name='Expensive', line=dict(color='orange')))
#                     fig.add_trace(go.Scatter(x=all_prices, y=np.array(cumulative['too_expensive'])*100, name='Too Expensive', line=dict(color='red')))
#
#                     # è£œåŠ©ç·šã¨ãƒ©ãƒ™ãƒ«è¡¨ç¤º
#                     for val, name, color in zip(
#                         [opp, idp, pme, pmc],
#                         ['OPPï¼ˆæœ€é©ï¼‰', 'IDPï¼ˆç„¡é–¢å¿ƒï¼‰', 'PMEï¼ˆä¸Šé™ï¼‰', 'PMCï¼ˆä¸‹é™ï¼‰'],
#                         ['purple', 'black', 'magenta', 'cyan']
#                     ):
#                         if val:
#                             fig.add_vline(x=val, line_dash='dash', line_color=color)
#                             fig.add_annotation(x=val, y=50, text=name, showarrow=False, textangle=90,
#                                                font=dict(color=color, size=12), bgcolor='white')
#
#                     fig.update_layout(
#                         title=f"{brand} - PSMåˆ†æ",
#                         xaxis_title="ä¾¡æ ¼ï¼ˆå††ï¼‰",
#                         yaxis_title="ç´¯ç©æ¯”ç‡ï¼ˆ%ï¼‰",
#                         height=400,
#                         hovermode="x unified",
#                         xaxis=dict(tickformat='d')
#                     )
#
#                     st.plotly_chart(fig, use_container_width=True)
#
# else:
#     st.info("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")


# %%

# %%

# %%

# %%

# %% [markdown]
# ğŸ¤©ã€€ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å‡„ã„ã‚ˆ

# %% [markdown] jupyter={"source_hidden": true}
# import streamlit as st
# import pandas as pd
# import numpy as np
# from sklearn.preprocessing import StandardScaler
# from sklearn.cluster import KMeans
# import plotly.graph_objects as go
# from scipy.interpolate import interp1d
#
# st.set_page_config(layout="wide")
# st.title("ğŸ’´ Van Westendorp PSM + ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æã‚¢ãƒ—ãƒª")
#
# @st.cache_data
# def load_data(uploaded_file):
#     return pd.read_csv(uploaded_file)
#
# def find_intersection(y1, y2, x):
#     diff = np.array(y1) - np.array(y2)
#     sign_change = np.where(np.diff(np.sign(diff)) != 0)[0]
#     if len(sign_change) == 0:
#         return None
#     i = sign_change[0]
#     try:
#         f = interp1d(diff[i:i+2], x[i:i+2])
#         return float(f(0))
#     except Exception:
#         return None
#
# uploaded_file = st.file_uploader("ğŸ“‚ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"])
#
# if uploaded_file is not None:
#     df = load_data(uploaded_file)
#
#     st.markdown("#### ğŸ” çµã‚Šè¾¼ã¿ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")
#     col1, col2 = st.columns(2)
#
#     with col1:
#         if 'å¹´é½¢' in df.columns:
#             min_age = int(df['å¹´é½¢'].min())
#             max_age = int(df['å¹´é½¢'].max())
#             selected_age_range = st.slider("å¹´é½¢ç¯„å›²", min_age, max_age, (min_age, max_age))
#         else:
#             selected_age_range = None
#
#         if 'æ€§åˆ¥' in df.columns:
#             gender_options = df['æ€§åˆ¥'].dropna().unique().tolist()
#             selected_gender = st.multiselect("æ€§åˆ¥", gender_options, default=gender_options)
#         else:
#             selected_gender = None
#
#         if 'è·æ¥­' in df.columns:
#             job_options = df['è·æ¥­'].dropna().unique().tolist()
#             selected_jobs = st.multiselect("è·æ¥­", job_options, default=job_options)
#         else:
#             selected_jobs = None
#
#     with col2:
#         if 'è³¼è²·é »åº¦' in df.columns:
#             freq_options = df['è³¼è²·é »åº¦'].dropna().unique().tolist()
#             selected_frequency = st.multiselect("è³¼è²·é »åº¦", freq_options, default=freq_options)
#         else:
#             selected_frequency = None
#
#         if 'é‡è¦è¦–ã™ã‚‹ã“ã¨1' in df.columns:
#             imp_options = df['é‡è¦è¦–ã™ã‚‹ã“ã¨1'].dropna().unique().tolist()
#             selected_importance = st.multiselect("é‡è¦è¦–ã™ã‚‹ã“ã¨1", imp_options, default=imp_options)
#         else:
#             selected_importance = None
#
#     # ================
#     # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†
#     # ================
#     filtered_df = df.copy()
#     if selected_age_range:
#         filtered_df = filtered_df[filtered_df['å¹´é½¢'].between(*selected_age_range)]
#     if selected_gender:
#         filtered_df = filtered_df[filtered_df['æ€§åˆ¥'].isin(selected_gender)]
#     if selected_jobs:
#         filtered_df = filtered_df[filtered_df['è·æ¥­'].isin(selected_jobs)]
#     if selected_frequency:
#         filtered_df = filtered_df[filtered_df['è³¼è²·é »åº¦'].isin(selected_frequency)]
#     if selected_importance:
#         filtered_df = filtered_df[filtered_df['é‡è¦è¦–ã™ã‚‹ã“ã¨1'].isin(selected_importance)]
#
#     st.markdown(f"### ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œã®å¯¾è±¡è€…æ•°: {len(filtered_df)} äºº")
#
#     # ======================
#     # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
#     # ======================
#     st.markdown("#### ğŸ§© ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°è¨­å®š")
#
#     # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã«ä½¿ã†ç‰¹å¾´é‡é¸æŠUIï¼ˆã‚«ãƒ†ã‚´ãƒªã¯ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼‰
#     candidate_features = ['å¹´é½¢', 'æ€§åˆ¥', 'è·æ¥­', 'è³¼è²·é »åº¦', 'é‡è¦è¦–ã™ã‚‹ã“ã¨1']
#     selected_features = st.multiselect("ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã«ä½¿ã†å±æ€§ã‚’é¸æŠã—ã¦ãã ã•ã„", candidate_features, default=['å¹´é½¢', 'æ€§åˆ¥', 'è³¼è²·é »åº¦'])
#
#     if len(selected_features) == 0:
#         st.warning("å°‘ãªãã¨ã‚‚1ã¤ä»¥ä¸Šã®ç‰¹å¾´é‡ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
#     else:
#         cluster_count = st.slider("ã‚¯ãƒ©ã‚¹ã‚¿æ•° (K)", 2, 10, 3)
#
#         # å‰å‡¦ç†ï¼šã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã¯label encodingï¼ˆç°¡æ˜“ç‰ˆï¼‰
#         from sklearn.preprocessing import LabelEncoder
#         X = filtered_df[selected_features].copy()
#
#         for col in X.columns:
#             if X[col].dtype == 'object' or X[col].dtype.name == 'category':
#                 le = LabelEncoder()
#                 X[col] = le.fit_transform(X[col].astype(str))
#
#         # æ¨™æº–åŒ–
#         scaler = StandardScaler()
#         X_scaled = scaler.fit_transform(X)
#
#         # KMeansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
#         kmeans = KMeans(n_clusters=cluster_count, random_state=42)
#         clusters = kmeans.fit_predict(X_scaled)
#
#         filtered_df['cluster'] = clusters
#
#         st.markdown(f"### ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœï¼ˆK={cluster_count}ï¼‰")
#         st.write(filtered_df[['ID'] + selected_features + ['cluster']])
#
#         # ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®äººæ•°è¡¨ç¤º
# #        st.markdown("#### ã‚¯ãƒ©ã‚¹ã‚¿äººæ•°åˆ†å¸ƒ")
# #        cluster_counts = filtered_df['cluster'].value_counts().sort_index()
# #        st.bar_chart(cluster_counts)
#
#
#         # ã‚¯ãƒ©ã‚¹ã‚¿äººæ•°åˆ†å¸ƒã®ä¸‹ã«è¿½åŠ 
#         st.markdown("#### ã‚¯ãƒ©ã‚¹ã‚¿å†…å®¹")
#     
#         num_clusters = filtered_df['cluster'].nunique()
#         
#         num_features = ['å¹´é½¢', 'SNSåˆ©ç”¨æ™‚é–“', 'å¹³å‡è³¼å…¥å˜ä¾¡']
#         cat_features = ['æ€§åˆ¥', 'è·æ¥­', 'è³¼è²·é »åº¦', 'ã‚­ãƒ£ãƒ©å‚¾å‘',"é‡è¦è¦–ã™ã‚‹ã“ã¨1","è³¼å…¥ã‚¹ã‚¿ã‚¤ãƒ«1"]
#
#         rows = []
#         
#         for c in range(num_clusters):
#             cluster_df = filtered_df[filtered_df['cluster'] == c]
#             n = len(cluster_df)
#             
#             row = {"ã‚¯ãƒ©ã‚¹ã‚¿": c, "äººæ•°": n}
#             
#             # æ•°å€¤ç‰¹å¾´é‡ã®å¹³å‡å€¤
#             for f in num_features:
#                 if f in cluster_df.columns:
#                     row[f"{f}å¹³å‡"] = round(cluster_df[f].mean(), 2)
#             
#             # ã‚«ãƒ†ã‚´ãƒªç‰¹å¾´é‡ã¯æœ€é »å€¤ã¨å‰²åˆã‚’è¡¨ç¤ºï¼ˆä¾‹ï¼‰
#             for f in cat_features:
#                 if f in cluster_df.columns:
#                     top_val = cluster_df[f].value_counts(normalize=True).idxmax()
#                     top_ratio = cluster_df[f].value_counts(normalize=True).max()
#                     row[f"{f}ï¼ˆæœ€å¤šï¼‰"] = f"{top_val} ({top_ratio:.1%})"
#             
#             rows.append(row)
#         
#         summary_df = pd.DataFrame(rows)
#         
#         st.dataframe(summary_df)
#
#
#
#
#
#
#         
#         # =======================
#         # ã‚¯ãƒ©ã‚¹ã‚¿åˆ¥PSMåˆ†æè¡¨ç¤º
#         # =======================
#         st.markdown("#### ğŸ“Š ã‚¯ãƒ©ã‚¹ã‚¿åˆ¥ Van Westendorp PSMåˆ†æ")
#
#         labels = ['too_cheap', 'cheap', 'expensive', 'too_expensive']
#         brands = sorted(set(col.split('_')[0] for col in df.columns if any(lbl in col for lbl in labels)))
#
#         cluster_tabs = st.tabs([f"Cluster {i}" for i in range(cluster_count)])
#
#         for cluster_id, tab in zip(range(cluster_count), cluster_tabs):
#             with tab:
#                 st.markdown(f"##### Cluster {cluster_id} ã®åˆ†æ")
#
#                 df_cluster = filtered_df[filtered_df['cluster'] == cluster_id]
#
#                 for brand in brands:
#                     brand_cols = [f"{brand}_{lbl}" for lbl in labels if f"{brand}_{lbl}" in df_cluster.columns]
#                     df_brand = df_cluster[df_cluster[brand_cols].notnull().any(axis=1)]
#
#                     if df_brand.empty:
#                         st.warning(f"{brand} ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
#                         continue
#
#                     price_data = {
#                         label: df_brand[f"{brand}_{label}"].dropna().astype(int).values
#                         for label in labels if f"{brand}_{label}" in df_brand.columns
#                     }
#
#                     valid_arrays = [arr for arr in price_data.values() if len(arr) > 0]
#                     if not valid_arrays:
#                         st.warning("æœ‰åŠ¹ãªä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
#                         continue
#
#                     all_prices = np.arange(
#                         min(np.concatenate(valid_arrays)),
#                         max(np.concatenate(valid_arrays)) + 1000,
#                         100
#                     )
#                     n = len(df_brand)
#
#                     cumulative = {
#                         'too_cheap': [np.sum(price_data.get('too_cheap', []) >= p) / n for p in all_prices],
#                         'cheap': [np.sum(price_data.get('cheap', []) >= p) / n for p in all_prices],
#                         'expensive': [np.sum(price_data.get('expensive', []) <= p) / n for p in all_prices],
#                         'too_expensive': [np.sum(price_data.get('too_expensive', []) <= p) / n for p in all_prices],
#                     }
#
#                     opp = find_intersection(cumulative['cheap'], cumulative['expensive'], all_prices)
#                     idp = find_intersection(cumulative['too_cheap'], cumulative['too_expensive'], all_prices)
#                     pme = find_intersection(cumulative['cheap'], cumulative['too_expensive'], all_prices)
#                     pmc = find_intersection(cumulative['expensive'], cumulative['too_cheap'], all_prices)
#
#                     fig = go.Figure()
#                     fig.add_trace(go.Scatter(x=all_prices, y=np.array(cumulative['too_cheap'])*100, name='Too Cheap', line=dict(color='blue')))
#                     fig.add_trace(go.Scatter(x=all_prices, y=np.array(cumulative['cheap'])*100, name='Cheap', line=dict(color='green')))
#                     fig.add_trace(go.Scatter(x=all_prices, y=np.array(cumulative['expensive'])*100, name='Expensive', line=dict(color='orange')))
#                     fig.add_trace(go.Scatter(x=all_prices, y=np.array(cumulative['too_expensive'])*100, name='Too Expensive', line=dict(color='red')))
#
#                     # è£œåŠ©ç·šã¨ãƒ©ãƒ™ãƒ«è¡¨ç¤º
#                     for val, name, color in zip(
#                         [opp, idp, pme, pmc],
#                         ['OPPï¼ˆæœ€é©ï¼‰', 'IDPï¼ˆç„¡é–¢å¿ƒï¼‰', 'PMEï¼ˆä¸Šé™ï¼‰', 'PMCï¼ˆä¸‹é™ï¼‰'],
#                         ['purple', 'black', 'magenta', 'cyan']
#                     ):
#                         if val:
#                             fig.add_vline(x=val, line_dash='dash', line_color=color)
#                             fig.add_annotation(x=val, y=50, text=name, showarrow=False, textangle=90,
#                                                font=dict(color=color, size=12), bgcolor='white')
#
#                     fig.update_layout(
#                         title=f"{brand} - PSMåˆ†æ",
#                         xaxis_title="ä¾¡æ ¼ï¼ˆå††ï¼‰",
#                         yaxis_title="ç´¯ç©æ¯”ç‡ï¼ˆ%ï¼‰",
#                         height=400,
#                         hovermode="x unified",
#                         xaxis=dict(tickformat='d')
#                     )
#
#                     st.plotly_chart(fig, use_container_width=True)
#
# else:
#     st.info("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

